{"cells":[{"cell_type":"markdown","metadata":{"id":"qscYaLAXnWnm"},"source":["# Trabalho de Ciência de Dados: Regressão Linear para Predição de Preços de Casas\n","\n","Neste notebook, você encontrará a estrutura básica para implementar um modelo de Regressão Linear do zero para prever preços de casas. Seu trabalho é preencher as funções com o código necessário para realizar as tarefas descritas.\n","\n","Lembre-se: Não use bibliotecas como sklearn ou outras que já tenham implementações prontas de regressão linear ou métricas de avaliação."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"neVi0iXAnWnr"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'numpy'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"b6UuDKPYnWnt"},"source":["## 1. Carregamento e Pré-processamento dos Dados\n","\n","Comece carregando os dados e realizando qualquer pré-processamento necessário."]},{"cell_type":"code","execution_count":43,"metadata":{"id":"3NcgSm81nWnu"},"outputs":[],"source":["def carregar_dados(caminho_arquivo = 'Housing.csv'):\n","    return pd.read_csv(caminho_arquivo) \n","\n","def preprocessar_dados(dados):\n","    # Colunas categóricas que precisam ser convertidas\n","    colunas_categoricas = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', \n","                           'airconditioning', 'prefarea', 'furnishingstatus']\n","    \n","    # Separando a coluna alvo (y) e as variáveis independentes (X)\n","    y = dados['price'].values.astype(float)  # Converta para float explicitamente\n","    X = dados.drop(columns=['price']).copy()\n","\n","    # Convertendo as colunas categóricas para variáveis dummy (one-hot encoding)\n","    X = pd.get_dummies(X, columns=colunas_categoricas, drop_first=True)\n","\n","    # Normalização dos dados (padronização: média 0, desvio padrão 1) apenas para variáveis numéricas\n","    colunas_numericas = X.select_dtypes(include=[np.number]).columns\n","    X_mean = X[colunas_numericas].mean()\n","    X_std = X[colunas_numericas].std()\n","\n","    # Evitar divisão por zero no caso de desvio padrão igual a zero\n","    X_std[X_std == 0] = 1\n","\n","    # Normalizando os dados\n","    X[colunas_numericas] = (X[colunas_numericas] - X_mean) / X_std\n","\n","    # Convertendo X para array numpy e garantindo tipo float\n","    X = X.values.astype(float)\n","\n","    return X, y\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hsdK65WFnWnv"},"source":["## 2. Implementação da Regressão Linear\n","\n","Agora, implemente as funções necessárias para a Regressão Linear usando o Gradiente Descendente.\n","\n","**Lembre-se:** o objetivo da Regressão Linear é descobrir os parâmetros $w$ (*slope*) e $b$ (*interceptador*), tal que a função linear $y = wx  + b$ tenha o menor erro possível."]},{"cell_type":"code","execution_count":40,"metadata":{"id":"f7mHmXjHnWnv"},"outputs":[],"source":["class RegressaoLinear:\n","    def __init__(self, learning_rate=0.01, num_iterations=1000):\n","        self.learning_rate = learning_rate\n","        self.num_iterations = num_iterations\n","        self.weights = None\n","        self.bias = None\n","\n","    def funcao_custo(self, X, y, weights, bias):\n","        m = len(y)\n","        previsao = np.dot(X, weights) + bias\n","        erro = previsao - y\n","        custo = (1 / (2 * m)) * np.sum(erro**2)  # Função de custo\n","        return custo\n","\n","    def gradiente_descendente(self, X, y, weights, bias):\n","        m = len(y)\n","        previsao = np.dot(X, weights) + bias\n","        erro = previsao - y\n","\n","        # gradiente\n","        dw = (1 / m) * np.dot(X.T, erro)\n","        db = (1 / m) * np.sum(erro)\n","\n","        # Converter para float para garantir que não ocorra o erro de casting\n","        weights = weights.astype(float)\n","        dw = dw.astype(float)\n","\n","        weights -= self.learning_rate * dw\n","        bias -= self.learning_rate * db\n","\n","        return weights, bias\n","\n","\n","    def treinar(self, X, y):\n","        m, n = X.shape\n","        self.weights = np.zeros(n)\n","        self.bias = 0\n","\n","        for i in range(self.num_iterations):\n","            self.weights, self.bias = self.gradiente_descendente(X, y, self.weights, self.bias)\n","\n","            if i % 100 == 0:\n","                custo = self.funcao_custo(X, y, self.weights, self.bias)\n","                print(f'Iteração {i}, Custo: {custo}')\n","\n","    def prever(self, X):\n","        return np.dot(X, self.weights) + self.bias"]},{"cell_type":"markdown","metadata":{"id":"IxnDvXYwnWnx"},"source":["## 3. Métricas de Avaliação\n","\n","Implemente as funções para calcular as métricas de avaliação do modelo."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"Ig4gCS75nWnx"},"outputs":[],"source":["def calcular_rmse(y_true, y_pred):\n","    return np.sqrt(np.mean((y_true - y_pred) ** 2))  # Corrigido: Agora eleva o erro ao quadrado\n","\n","def calcular_mae(y_true, y_pred):\n","    return np.mean(np.abs(y_true - y_pred))\n","\n","def calcular_mape(y_true, y_pred):\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","## Função para dividir treino e teste\n","def dividir_treino_teste(X, y, test_size=0.2):\n","    n_total = X.shape[0]\n","    n_teste = int(n_total * test_size)\n","\n","    # Embaralhar os dados\n","    indices = np.random.permutation(n_total)\n","    indices_teste = indices[:n_teste]\n","    indices_treino = indices[n_teste:]\n","\n","    X_treino, X_teste = X[indices_treino], X[indices_teste]\n","    y_treino, y_teste = y[indices_treino], y[indices_teste]\n","\n","    return X_treino, X_teste, y_treino, y_teste"]},{"cell_type":"markdown","metadata":{"id":"amXhuWwYnWny"},"source":["## 4. Treinamento e Avaliação do Modelo\n","\n","Use as funções implementadas para treinar o modelo e avaliar seu desempenho."]},{"cell_type":"code","execution_count":44,"metadata":{"id":"SpMd3h5MnWnz"},"outputs":[{"ename":"UFuncTypeError","evalue":"Cannot cast ufunc 'subtract' output from dtype('O') to dtype('float64') with casting rule 'same_kind'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[44], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Crie e treine o modelo\u001b[39;00m\n\u001b[0;32m      9\u001b[0m modelo \u001b[38;5;241m=\u001b[39m RegressaoLinear()\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtreinar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_treino\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_treino\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Faça previsões\u001b[39;00m\n\u001b[0;32m     13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m modelo\u001b[38;5;241m.\u001b[39mprever(X_teste)\n","Cell \u001b[1;32mIn[40], line 35\u001b[0m, in \u001b[0;36mRegressaoLinear.treinar\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_iterations):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradiente_descendente\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     38\u001b[0m         custo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuncao_custo(X, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n","Cell \u001b[1;32mIn[40], line 24\u001b[0m, in \u001b[0;36mRegressaoLinear.gradiente_descendente\u001b[1;34m(self, X, y, weights, bias)\u001b[0m\n\u001b[0;32m     21\u001b[0m dw \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X\u001b[38;5;241m.\u001b[39mT, erro)\n\u001b[0;32m     22\u001b[0m db \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(erro)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdw\u001b[49m\n\u001b[0;32m     25\u001b[0m bias \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m db\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights, bias\n","\u001b[1;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'subtract' output from dtype('O') to dtype('float64') with casting rule 'same_kind'"]}],"source":["# Carregue e pré-processe os dados\n","dados = carregar_dados('Housing.csv')\n","X, y = preprocessar_dados(dados)\n","\n","# Divida os dados em conjuntos de treino e teste\n","X_treino, X_teste, y_treino, y_teste = dividir_treino_teste(X, y, test_size=0.2)\n","\n","# Crie e treine o modelo\n","modelo = RegressaoLinear()\n","modelo.treinar(X_treino, y_treino)\n","\n","# Faça previsões\n","y_pred = modelo.prever(X_teste)\n","\n","# Calcule e imprima as métricas\n","rmse = calcular_rmse(y_teste, y_pred)\n","mae = calcular_mae(y_teste, y_pred)\n","mape = calcular_mape(y_teste, y_pred)\n","\n","print(f'RMSE (Teste): {rmse:.5f}')\n","print(f'MAE (Teste): {mae:.5f}')\n","print(f'MAPE (Teste): {mape:.5f}')\n"]},{"cell_type":"markdown","metadata":{"id":"yqTC3Ua5nWnz"},"source":["## 5. Visualização dos Resultados\n","\n","Crie visualizações para ajudar a interpretar os resultados do seu modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ea8fjquanWn0"},"outputs":[],"source":["def plotar_resultados(y_teste, y_pred):\n","    plt.figure(figsize=(10, 6))\n","    plt.scatter(y_teste, y_pred, color='blue', label='Valores Previstos')\n","    plt.plot([y_teste.min(), y_teste.max()], [y_teste.min(), y_teste.max()], color='red', lw=2, label='Linha Ideal')\n","    plt.xlabel('Valores Reais')\n","    plt.ylabel('Valores Previstos')\n","    plt.title('Valores Reais vs. Valores Previstos')\n","    plt.legend()\n","    plt.show()\n","\n","plotar_resultados(y_teste, y_pred)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":0}
